{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring nonparametric methods - Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in these Tutorials, we have focused on parametric methods - methods that assume a specific function family, from which the optimal function is selected to fit the data. This works well if we are quite sure that the data can be assumed to be well described by this family of functions. Non-parametric methods do not prescribe a specific form to the fitted model. Instead, the model can take any shape or form. This makes the model highly flexible, but also quite data-hungry. Non-parametric methods are therefore usually employed when the data is non-linear, the relationship between the variables is complex or unknown and/or it is not clear which of the variables could be the most important one.\n",
    "\n",
    "In the first part of this exercise, we will use an artificial three-dimensional dataset describing a highly non-linear shape (\"droplet\" data from the lecture). We will first try to fit a parametric linear and a parametric non-linear function (Linear Regression and Polynomial Regression) to it and assess the goodness of fit. After that we will attempt to use non-parametric methods (Kernel Smoother and Regression Tree) and see the advantages of this method for this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(raster)\n",
    "library(rworldmap)\n",
    "library(RColorBrewer)\n",
    "library(kknn)\n",
    "library(locfit)\n",
    "library(tree)\n",
    "require(randomForest)\n",
    "\n",
    "source(\"functions.R\")\n",
    "source('../Exercise2/functions.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create artificial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the nonlinear artificial data set. This data set will be used to showcase the capabilities of the individual methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create explanatory variables\n",
    "yy.lim <- xx.lim <- c(-10,10)\n",
    "xx <- seq(min(xx.lim),max(xx.lim),length.out=100)\n",
    "yy <- seq(min(yy.lim),max(yy.lim),length.out=100)\n",
    "\n",
    "## Get all combinations of xx and yy\n",
    "xy.mat <- expand.grid(x=xx,y=yy)\n",
    "\n",
    "## Function for creating artificial response variable\n",
    "zz.fun <- function(x,y){\n",
    "    r <- sqrt(x^2+y^2)\n",
    "    ro <- 10 * sin(r)/r\n",
    "    return(ro)\n",
    "}\n",
    "\n",
    "## Compute z for all combinations x and y\n",
    "data <- data.frame(xy.mat,z=zz.fun(x=xy.mat$x,y=xy.mat$y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the created data and try to understand its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(data)\n",
    "\n",
    "# Size of the data set\n",
    "sprintf(\"Size of the overall dataset: %i\",(N.data <- nrow(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of three variables `x`, `y`and `z`. Each of the variables has 10000 observations. Since we created it with the mathematical expressions from above, it is noise-free. We add normal distributed noise to each value of `z`(our predictand) to create a typical statistical learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(101)   ## makes random number generation reproducible\n",
    "noise.sd <- 0.5 ## standard deviation of noise; you can change it if you want\n",
    "data$z.noisy <- data$z + rnorm(nrow(data),mean=0,sd=noise.sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into a *test* and a *training* set randomly. Half of the data is in the test set, the other half in the training set. You can change the fraction of test data (now 0.5) if you want. The larger the test set is, the smaller is the training set. Since our methods are data-hungry, a small training set might make it more difficult to come up with a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use half of the data for training:\n",
    "frac.test <- 0.5\n",
    "\n",
    "## Get indices of test data:\n",
    "test.ind <- sample(N.data,round(frac.test*N.data))\n",
    "\n",
    "## Select test data:\n",
    "test.data <- data[test.ind,]\n",
    "\n",
    "## Select training data:\n",
    "train.data <- data[-test.ind,]\n",
    "\n",
    "## Size of training data\n",
    "sprintf(\"Size of training dataset: %i\",(N.train.data <- nrow(train.data)))\n",
    "\n",
    "## Size of test data\n",
    "sprintf(\"Size of testing dataset: %i\",(N.test.data <- nrow(test.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, an overview of the created dataset. In the first plot, you see the true function that we have created. In the second, you see the dataset after we have added the normally distributed noise in the `z` direction. The two lower panels show the points belonging to test and training set, respectively.\n",
    "\n",
    "This is the dataset that we will now use to fit our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=data$z,axnames=T,title=\"True function\")\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=data$z.noisy,title=\"True function + noise\")\n",
    "plot.xyz.persp(x=train.data$x,y=train.data$y,z=train.data$z.noisy,title=\"Training data\")\n",
    "plot.xyz.persp(x=test.data$x,y=test.data$y,z=test.data$z.noisy,title=\"Testing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good ol' Linear & Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try some well known parametric models that you already know, a Linear Regression and a Polynomial Regression. You might already think that it is not the optimal idea to fit a Linear Regression to the training dataset. However, you might have a less clear idea if a Polynomial Regression could sufficiently model the data. Let's try both and see if we understand what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "\n",
    "## Fit linear regression model and make prediction:\n",
    "lm.fit <- lm(z.noisy~x+y,data=train.data)\n",
    "print(lm.fit$coefficients)\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(lm.fit,newdata=data),axnames=T,title=\"Linear Regression Prediction\")\n",
    "\n",
    "## Fit polynomial regression of order 6 (with interactions):\n",
    "lm.poly.fit <- lm(z.noisy~poly(x,6) * poly(y,6),data=train.data)\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(lm.poly.fit,newdata=data),axnames=T,title=\"Polynomial Regression Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- What does the Linear Regression predict?\n",
    "- How does the pattern in polynomial regression evolve?\n",
    "- Why do we need more complex models for this type of data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Smoother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleary, other methods are necessary in this case. In the lecture you have learned about a model class we called \"Kernel Smoothers\". Sometimes they are also called LOESS functions (\"local estimated scatterplot smoothing\").\n",
    "\n",
    "This family of methods locally approximate a simple (e.g. linear) function and puzzle together those linear approxmations to retrieve a global function. K-nearest neighbor Regression, a method that we already extensively used in the last tutorials, can also be viewed as a Kernel Smoother, where the local approximation is simply the mean of the $k$ nearest neighboring datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good ol' knn (now in 2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and speed, we start with a subset of the training data, choosing randomly 100 data points from the 5000 training data points. We exemplarily choose 1, 10 and 100 as $k$ values and plot the prediction surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Length of sub training dataset:\n",
    "n_sub <- 102\n",
    "\n",
    "## Define for which k-parameters you fit you knn-model:\n",
    "k_vec <- c(1,10,100)\n",
    "predictions <- list()\n",
    "par(mfrow=c(2,2))\n",
    "for(k in k_vec) {\n",
    "    time_start <- Sys.time()\n",
    "    \n",
    "    ## 1) \"Train\" the model:\n",
    "    fit.train <- train.kknn(z.noisy~x+y, train.data[sample(1:nrow(train.data), n_sub),], ks = k, kernel = \"rectangular\")\n",
    "    \n",
    "    ## 2) Get the predictions:\n",
    "    predictions[[paste0(\"k\",k)]] <- predict(fit.train,newdata=data)\n",
    "    \n",
    "    ## 4) Plot the predictions:\n",
    "    plot.xyz.persp(x=data$x,y=data$y,z=predictions[[paste0(\"k\",k)]], axnames=T,title=paste(\"knn Prediction\\nk =\",k))\n",
    "    \n",
    "    #print(paste(\"Time required for fit & prediction for k =\",k))\n",
    "    #print(Sys.time()-time_start)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- Why does the prediction surface get \"flatter\" when $k$ is increased?\n",
    "- What is the prediction for k=100?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the same analysis for the full training dataset (N=5000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define for which k-parameters you fit you knn-model:\n",
    "k_vec <- c(1,10,100,1000)\n",
    "predictions <- list()\n",
    "par(mfrow=c(2,2))\n",
    "for(k in k_vec) {\n",
    "    time_start <- Sys.time()\n",
    "    \n",
    "    ## 1) \"Train\" the model:\n",
    "    fit.train <- train.kknn(z.noisy~x+y, train.data, ks = k, kernel = \"rectangular\")\n",
    "    \n",
    "    ## 2) Get the predictions:\n",
    "    predictions[[paste0(\"k\",k)]] <- predict(fit.train,newdata=data)\n",
    "    \n",
    "    ## 4) Plot the predictions:\n",
    "    plot.xyz.persp(x=data$x,y=data$y,z=predictions[[paste0(\"k\",k)]], axnames=T,title=paste(\"knn Prediction\\nk =\",k))\n",
    "    \n",
    "    #print(paste(\"Time required for fit & prediction for k =\",k))\n",
    "    #print(Sys.time()-time_start)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- Why the strange interpolation with k=1000?\n",
    "- How would you decide on which k parameter is optimal?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other kernels (introduced in week 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Kernel Smoothers use more complex functions than just the mean of $k$ neighbors. Here are the results with some kernels that we discussed during the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/kernels.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a low number of training data points, such that the effect becomes visible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Length of sub training dataset:\n",
    "n_sub <- 200\n",
    "\n",
    "## Set k (leave NULL for the moment)\n",
    "k_fix <- NULL\n",
    "\n",
    "## 1) Train the model with internal search for optimal k (similar to cross-validation, with nfolds=N,\n",
    "##    so-called \"leave-one-out method\"):\n",
    "zz.knn.rect.opt <- train.kknn(z.noisy~x+y, train.data[sample(1:nrow(train.data), n_sub),],\n",
    "                              kmax=50,ks=k_fix,kernel=\"rectangular\")\n",
    "zz.knn.epan.opt <- train.kknn(z.noisy~x+y, train.data[sample(1:nrow(train.data), n_sub),],\n",
    "                              kmax=50,ks=k_fix,kernel=\"epanechnikov\")\n",
    "zz.knn.triw.opt <- train.kknn(z.noisy~x+y, train.data[sample(1:nrow(train.data), n_sub),],\n",
    "                              kmax=50,ks=k_fix,kernel=\"triweight\")\n",
    "zz.knn.norm.opt <- train.kknn(z.noisy~x+y, train.data[sample(1:nrow(train.data), n_sub),],\n",
    "                              kmax=50,ks=k_fix,kernel=\"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Plot the predictions:\n",
    "par(mfrow=c(2,2))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.knn.rect.opt,newdata=data),\n",
    "               title=paste(\"knn Prediction\\nk =\",zz.knn.rect.opt$best.parameters$k))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.knn.epan.opt,newdata=data),\n",
    "               title=paste(\"Epanechnikov Kernel Prediction\\nbandwidth =\",zz.knn.epan.opt$best.parameters$k))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.knn.triw.opt,newdata=data),\n",
    "               title=paste(\"Tri-cube Kernel Prediction\\nbandwidth =\",zz.knn.triw.opt$best.parameters$k))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.knn.norm.opt,newdata=data),\n",
    "               title=paste(\"Gaussian Kernel Prediction\\nbandwidth =\",zz.knn.norm.opt$best.parameters$k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- How would the \"kernel\" for knn look like in the plot taken from the lecture slides?\n",
    "- How do the different kernel predictions differ?\n",
    "- Fix a certain k (instead of having ```k <- NULL```, set e.g. ```k <- 20```), what is the effect of the neighbourhood size / bandwidth?\n",
    "- How do these methods differe for larger training sets (change ```n_sub <- 200``` to a larger value)?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another easy Kernel Smoother is fitting a local regression function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define fraction of points which should be considered for fitting:\n",
    "n_frac <- 0.1\n",
    "\n",
    "## Length of sub training dataset:\n",
    "n_sub <- 200\n",
    "\n",
    "## Fit local regression (linear and quadratic):\n",
    "zz.locfit.1deg <- locfit(z.noisy~lp(x, y, nn=n_frac, deg=1),\n",
    "                         data=train.data[sample(1:nrow(train.data), n_sub),])\n",
    "zz.locfit.2deg <- locfit(z.noisy~lp(x, y, nn=n_frac, deg=2),\n",
    "                         data=train.data[sample(1:nrow(train.data), n_sub),])\n",
    "\n",
    "## Plot the local regression predictions:\n",
    "par(mfrow=c(1,2))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.locfit.1deg,newdata=data),\n",
    "               title=sprintf(\"Local regression\\nlinear, n/n_tot = %.1f%%\",n_frac*100))\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=predict(zz.locfit.2deg,newdata=data),\n",
    "               title=sprintf(\"Local regression\\nquadratic, n/n_tot = %.1f%%\",n_frac*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- What happens when only a small fraction of training data points is used for the local regression fitting (e.g. setting ```n <- 0.05``` or lower)?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another family of non-parametric methods are Decision Trees. Decision Trees are often also used outside the statistical learning context to visualise the process of decision making: \n",
    "\n",
    "<img src=\"figures/decision_tree.png\" width=400 height=450 />\n",
    "\n",
    "\n",
    "They can equivalently be used in Statistical Learning to divide the data into *leaves*. Going down a constructed decision tree will give a prediction for any new datapoints. Decision Trees have much more hyperparameters than many methods (remember that a Ridge Regression has only one, $\\lambda$) that have to be set using Cross-Validation. Some of the important hyperparameters are:\n",
    "\n",
    "- the number of data points `minsize` remaining in a node below which the node is a *leaf* (i.e. the tree is no further branched from there)\n",
    "- the difference between two nodes after a split is made `mindev` as a fraction of the deviance of the root node. The smaller this hyperparameter is, the more splits are made, even if the explained differences between the two nodes is small (potentially overfitting the noise).\n",
    "- the number of variables $m$ from the full set of predictors that is used to split at each node\n",
    "\n",
    "In R, `tree` works with the *formula* interface. It has many settings, we will use some of them later. You can inspect the documentation of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the documentation for the function for fitting a regression tree\n",
    "?tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the documentation for the function for making predictions\n",
    "?predict.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by growing a simple Decision Tree with the default settings on our artificial test dataset and inspect the resulting tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build simple tree:\n",
    "tree.simple.fit <- tree(z.noisy~x+y,data=train.data)\n",
    "\n",
    "## Summarise the tree\n",
    "summary(tree.simple.fit)\n",
    "\n",
    "## Plot the tree structure\n",
    "plot(tree.simple.fit)\n",
    "text(tree.simple.fit)\n",
    "\n",
    "## Predict both test data (for error measures) and full dataset (for plotting):\n",
    "tree.test.pred <- predict(tree.simple.fit,newdata=test.data)\n",
    "tree.full.pred <- predict(tree.simple.fit,newdata=data)\n",
    "\n",
    "## Plot full tree:\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=tree.full.pred)\n",
    "legend(\"topright\",legend=c(sprintf(\"MSE: %.2f\",MSE(obs=test.data$z.noisy,pred=tree.test.pred)),\n",
    "                           sprintf(\"R2: %.2f\", R2(obs=test.data$z.noisy,pred=tree.test.pred))),\n",
    "       bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the tree structure with the prediction surface to get a feeling how the Decision Tree works. For example, you can imagine an arbitrary value for `x` and `y`, go down the tree and see in which leaf you end up. Then compare to the 3D plot to find the corresponding plateau in the prediction surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- Can you identify the splits in the plot above (the X and Y axis go from -10 to 10)?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the plot above the MSE and R2 of the resulting tree. As you might have already guessed by visually inspecting the prediction surface, this tree is too simple to predict the complex dataset that we have created.  This is because in the default settings, `mindev` and `minsize` are set such that the tree growth is quite restricted. \n",
    "\n",
    "To allow the tree to grow larger, we set the minimum within-node deviance `mindev` and the number of data points in the terminal leaf `minsize` to smaller values. Compare the two plots, MSE and R2 to see that indeed the tree has a better performance now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build tree:\n",
    "tree.full.fit <-  tree(z.noisy~x+y,data=train.data,\n",
    "                       mindev=0.00001,\n",
    "                       minsize=1) \n",
    "summary(tree.full.fit)\n",
    "\n",
    "## Predict both test data (for error measures) and full dataset (for plotting):\n",
    "tree.full.test.pred <- predict(tree.full.fit,newdata=test.data)\n",
    "tree.full.full.pred <- predict(tree.full.fit,newdata=data)\n",
    "\n",
    "## Plot full tree\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=tree.full.full.pred)\n",
    "legend(\"topright\",legend=c(sprintf(\"MSE: %.2f\",MSE(obs=test.data$z.noisy,pred=tree.full.test.pred)),\n",
    "                           sprintf(\"R2: %.2f\", R2(obs=test.data$z.noisy,pred=tree.full.test.pred))),\n",
    "       bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- How many terminal nodes do the two trees have?\n",
    "- Do you expect that the predictions closely match the \"true values\"? \n",
    "- What method would you use to find the optimal pruning parameter?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, as it is already deeply ingrained in our statistical learning \"minds\", one does not simply set a hyper parameter. The course towards finding optimal parameters for any method is always *mighty* **Cross-Validation**.\n",
    "\n",
    "Exemplarily, we explore now the optimal setting for the number of terminal nodes `minsize`.\n",
    "\n",
    "(If we would cross-fit more than one of the many Tree parameters, Cross-Validation happens accross many dimensions and can quickly become expensive.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "ATTENTION: This cell might take a minute or so...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set seed (initial value of random number generator to make results reproducable)\n",
    "set.seed(102)\n",
    "tree.opt.cv <- modified.cv.tree(tree.full.fit,K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find minimal residual sum of Squares (like MSE, just not the mean but the sum)\n",
    "## and the associated optimal tree size (number of terminal nodes):\n",
    "size_min <- which.min(tree.opt.cv$dev)\n",
    "plot(tree.opt.cv$size,tree.opt.cv$dev,\n",
    "     type=\"b\",log=\"xy\",xlab=\"Number of terminal nodes\",ylab=\"Deviance = RSS\")\n",
    "grid()\n",
    "abline(v=tree.opt.cv$size[size_min], col=\"red\")\n",
    "points(tree.opt.cv$size[size_min] ,tree.opt.cv$dev[size_min],pch=19,col=\"red\")\n",
    "legend(\"topright\",\n",
    "       legend=sprintf(\"# Nodes = %i at RSS = %.1f\",tree.opt.cv$size[size_min],\n",
    "                      tree.opt.cv$dev[size_min]),\n",
    "       lwd=1,col=\"red\",bg=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal tree has 336 terminal nodes. We plot the prediction surface and inspect MSE and R2 of this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prune to optimal tree:\n",
    "optimal.tree <- prune.tree(tree.full.fit,best=tree.opt.cv$size[size_min])\n",
    "\n",
    "## Get prediction on test data and full dataset:\n",
    "optimal.tree.test.prediction <- predict(optimal.tree,newdata=test.data)\n",
    "optimal.tree.full.prediction <- predict(optimal.tree,newdata=data)\n",
    "\n",
    "## Plot optimal prediction:\n",
    "plot.xyz.persp(x=data$x,y=data$y,z=optimal.tree.full.prediction)\n",
    "legend(\"topright\",legend=c(sprintf(\"MSE: %.2f\",MSE(obs=test.data$z.noisy,pred=optimal.tree.test.prediction)),\n",
    "                           sprintf(\"R2: %.2f\", R2(obs=test.data$z.noisy,pred=optimal.tree.test.prediction))),\n",
    "       bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lecture, you have learned about Bagging (Bootstrap aggregating). Bagging means fitting the selected model repeatedly on a bootstrap sample of the data (a sample with replacement, in German \"Ziehen mit Zurücklegen\", i.e. a datapoint can be more than once in this dataset). This can improve accuracy considerably. \n",
    "\n",
    "Since it is easier to understand the concept of Bagging in a 1D-model, we re-use the artificial dataset created in the first exercise, witch is a 1D slice of our 2D droplet dataset (used in the first part of this exercise) with added noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load function to create dataset from exercise 1:\n",
    "source('../Exercise1/functions.R')\n",
    "\n",
    "## Generate 200 training sample points:\n",
    "train.data = generate.data.poly(N=200, seed=200, sd.noise=0.15)\n",
    "\n",
    "## Plot true function and training dataset:\n",
    "plot(train.data$X, train.data$Y_true, lwd=2, type=\"l\", ylim=c(-0.5,1),axes=F, xaxt='n', ann=FALSE)\n",
    "points(train.data$X, train.data$Y,col=\"darkgrey\")\n",
    "legend(\"topleft\",legend=c(\"True\",\"Train\"),col=c(\"black\",\"darkgrey\"),\n",
    "       lty=c(1,NA),pch=c(NA,1),lwd=2, bty = \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataset, we now want to iteratively fit Decision Trees on \"bagged\" sampled of the data.\n",
    "\n",
    "For that we first, we define a function, which takes the training data ```dat``` and the points for which it should make a prediction ```x.pred```, draws a random sample (with replacement ```replace=T```, of size N ```size=nrow(dat)```), fits a regression tree to this subsample and returns the predictions at ```x.pred```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function which does the bagging (selects sample of training data, \n",
    "## fits a tree, returns predictions):\n",
    "tree_bagging_prediction <- function(dat,x.pred,return.ind_sample=F) {\n",
    "    ind_sample <- sample(1:nrow(dat), size=nrow(dat), replace=T)\n",
    "    tree.bag.fit <-  tree(Y~X,data=dat[ind_sample,],\n",
    "                       mindev=0.005,\n",
    "                       minsize=1) \n",
    "    tree.bag.test.pred <- predict(tree.bag.fit,newdata=data.frame(X=x.pred))\n",
    "    if(return.ind_sample) {return(list(pred=tree.bag.test.pred, ind.samp=ind_sample))}\n",
    "    else {return(tree.bag.test.pred)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute this function four times, resulting in four \"bagged\" estimates for the fitted Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "set.seed(1234)\n",
    "for(i in 1:4) {\n",
    "    res <- tree_bagging_prediction(train.data, x.pred=seq(0,15,0.01),return.ind_sample=T)\n",
    "    plot(train.data$X, train.data$Y, ylim=c(-0.5,1),axes=F, xaxt='n', ann=FALSE,col=\"darkgrey\")\n",
    "    points(train.data$X[res$ind.samp], train.data$Y[res$ind.samp],col=\"lightcoral\",lwd=1.5)\n",
    "    lines(seq(0,15,0.01), res$pred, col=\"red\", type=\"s\", lwd=2)\n",
    "    if(i==1) legend(\"topleft\", legend=c(\"Sample points\",\"Tree prediction\"), col=c(\"lightcoral\",\"red\"),\n",
    "                    pch=c(\"o\",\"-\"), bty=\"n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that between plots the data points that are used for training are different, and the resulting Decision Tree functions also differ.\n",
    "\n",
    "We can considerably improve this prediction by repeating the bagging procedure 200 times and plot the median prediction and the 95% prediction interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get bagging predictions for 100 replicates:\n",
    "set.seed(321)\n",
    "bag_res <- replicate(200, tree_bagging_prediction(dat=train.data,x.pred=seq(0,15,0.01)), simplify = T)\n",
    "\n",
    "## Obtain 2.5% and 97.5% quantiles:\n",
    "bag_res_quantiles <- apply(bag_res,1,quantile,c(0.025,0.5,0.975))\n",
    "\n",
    "## Plot single bagging predictions and 95%-CI prediction interval: \n",
    "matplot(x=seq(0,15,0.01), y=bag_res, col=rgb(1,0,0,0.2),type=\"s\",\n",
    "        ylim=c(-0.5,1),axes=F, xaxt='n', ann=FALSE, lty=1)\n",
    "polygon(x=c(seq(0,15,0.01),rev(seq(0,15,0.01))),\n",
    "        y=c(bag_res_quantiles[1,],rev(bag_res_quantiles[3,])),\n",
    "        col=rgb(200,90,1,alpha=150,maxColorValue=255),border=rgb(200,90,1,maxColorValue=255))       \n",
    "lines(seq(0,15,0.01), bag_res_quantiles[2,], lwd=2, type=\"l\", col=\"yellow\")\n",
    "lines(train.data$X, train.data$Y_true, lwd=2, type=\"l\")\n",
    "points(train.data$X, train.data$Y,col=\"darkgrey\")\n",
    "legend(\"topleft\", legend=c(\"95% prediction interval\",\"Single tree prediction\",\"Median prediction\"), lwd=c(NA,1,2),\n",
    "       fill=c(rgb(200,90,1,alpha=200,maxColorValue=255),NA,NA),\n",
    "       border=c(rgb(200,90,1,maxColorValue=255),NA,NA),\n",
    "       col=c(NA,rgb(1,0,0,0.5),\"yellow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usually unknown \"true function\" (in black) is within the envelope of the percentiles. With the median, we have created a bagged Decision Tree estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest is *almost* the same as a bagged Decision Tree - remember how in the lecture we discussed the two randomizations of Random Forests: (1) Bagging of data points (as done above) and (2) selecting randomly a subset of variables for the prediction. Since above we only had a 1D dataset, it does not make sense to select a subset of variables.\n",
    "\n",
    "Therefore, we switch to another dataset - the PSL/precipitation dataset that you might remember from the first lecture, where we predicted precipitation in Zürich using the sea level pressure (PSL) of surrounding grid points. This is how the data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | y | X_1 | X_2 | ... | X_p |\n",
    "| :- | :- | :- | :- | :- | :- |\n",
    "| | Precip_Zurich | PSL_lon$_1$lat$_1$ | PSL_lon$_2$lat$_1$ | .... | PSL_lon$_x$lat$_y$ |\n",
    "| December year$_1$ | 0.242 | 156 | 81.5 | ... | ... | \n",
    "| January year$_2$ | -1.115 | 63.5 | 78 | ... | ... | \n",
    "| February year$_2$ | 2.129 | 78 | 117 | ... | ... | \n",
    "| December year$_2$ | -1.574 | 128.81 | -207.7 | ... | ... | \n",
    "| January year$_3$ | -1.333 | 170.6 | 53.3 | ... | ... | \n",
    "| ... |... | ... | ... | ... | ... | \n",
    "| December year$_n$ | ... | ... | ... | ... | ... | \n",
    "| January year$_n$ | ... | ... | ... | ... | ... | \n",
    "| February year$_n$ | ... | ... | ... | ... | ... | \n",
    "\n",
    "<img src=\"figures/Precip_PSL.png\" width=300 height=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and divide into training and validation parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from Exercise 2 Part 1:\n",
    "load(\"data/Exercise3_Part1_Data.RData\")\n",
    "str(Precip_PSL_df[,1:3])\n",
    "\n",
    "## Rename predictor column names (otherwise the function call \"Precip_Zurich ~ .\" would not work):\n",
    "Precip_PSL_df_new <- Precip_PSL_df\n",
    "names(Precip_PSL_df_new)[2:ncol(Precip_PSL_df_new)] <- paste0(\"PSL\",1:(ncol(Precip_PSL_df_new)-1))\n",
    "\n",
    "## Specify training and validation indices:\n",
    "set.seed(1234)\n",
    "ind_train     <- sample(1:nrow(Precip_PSL_df), 2700)\n",
    "ind_test      <- which(!(1:nrow(Precip_PSL_df) %in% ind_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a random forest model. The parameter ```mtry``` specifies the number of variables randomly sampled at each split, which we called `m`in the lecture. The default value here is 33%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "ATTENTION: This cell might take a minute or so...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set fraction of variables which should be chosen randomly each split:\n",
    "rnd_var_frac <- 0.3\n",
    "\n",
    "## Set number of trees:\n",
    "ntrees <- 100\n",
    "\n",
    "set.seed(42)\n",
    "rf.fit.var.imp <- randomForest(Precip_Zurich ~ .,\n",
    "                               data=Precip_PSL_df_new[ind_train,],\n",
    "                               ntree=ntrees,\n",
    "                               mtry=floor(ncol(Precip_PSL_df_new[ind_train,])*rnd_var_frac),\n",
    "                               importance=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the Variable Importance of all the variables (sea level pressure at different locations) on a map to see which grid cell was most important for fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get feature importance:\n",
    "imp <- importance(rf.fit.var.imp,type=2)\n",
    "\n",
    "## Define colour scale:\n",
    "col.div    <- colorRampPalette(rev(brewer.pal(n = 9, name = \"OrRd\")))(10)\n",
    "ticks<- c(1,10,100,1000)\n",
    "\n",
    "## Get coordinate grid and make spatial raster object:\n",
    "spatial_raster <- raster(SpatialPixels(SpatialPoints(coords = coord_grid,\n",
    "                         proj4string = CRS(projargs = \"+proj=longlat\"))))\n",
    "\n",
    "## Plot mean PSL values of first month:\n",
    "par(mfrow=c(1,1), mar=c(6.5,12.5,3,1))\n",
    "plot.raster <- assign_values(log10(imp), spatial_raster)\n",
    "plot(plot.raster, col = col.div, main=\"Random Forest\\nVariable Importance\",\n",
    "     axis.args=list( at=log10(ticks), labels=ticks))\n",
    "plot(countriesCoarse, add = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the sea level pressure in grid cells close to Zürich have most predictive power for the estimation of precipitation at the Zürich grid point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- In which settings are non-parameteric functions better, in which settings is a parametric model sufficient?\n",
    "- In which settings does a tree work well?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bonus] compare Random Forest, knn and Decision Tree for real world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison with the Random Forest, we also fit a knn model (k=1) and optimised tree model to the PSL/precip data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "ATTENTION: This cell might take a minute or so...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit knn model and make prediction on test dataset:\n",
    "knn.fit.train.PSL <- train.kknn(Precip_Zurich~., data=Precip_PSL_df[ind_train,], ks = 1, kernel = \"rectangular\")\n",
    "knn.Precip.test.prediction <- predict(knn.fit.train.PSL,newdata=Precip_PSL_df[ind_test,])\n",
    "\n",
    "\n",
    "## Fit full tree model, optimise size using CV, prune full tree and make prediction on test dataset:\n",
    "tree.Precip.full.fit <-  tree(Precip_Zurich ~ .,\n",
    "                              data=Precip_PSL_df_new[ind_train,],\n",
    "                              mindev=0.002,\n",
    "                              minsize=1) \n",
    "\n",
    "tree.Precip.opt.cv <- modified.cv.tree(tree.Precip.full.fit,K=10)\n",
    "size_min <- which.min(tree.Precip.opt.cv$dev)\n",
    "\n",
    "optimal.Precip.tree <- prune.tree(tree.Precip.full.fit,best=tree.Precip.opt.cv$size[size_min])\n",
    "\n",
    "tree.Precip.test.prediction <- predict(optimal.Precip.tree, newdata=Precip_PSL_df_new[ind_test,])\n",
    "\n",
    "\n",
    "## Make prediction with random forest model (fitted above) on test dataset:\n",
    "rf.Precip.test.prediction <- predict(rf.fit.var.imp, newdata=Precip_PSL_df_new[ind_test,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare prediction with validation (test) data:\n",
    "plot_range <- range(Precip_PSL_df$Precip_Zurich[ind_test],knn.Precip.test.prediction)\n",
    "plot(Precip_PSL_df$Precip_Zurich[ind_test],knn.Precip.test.prediction,col=\"salmon\",\n",
    "     xlab=\"True precip values [mm/d]\",ylab=\"Predicted precip values [mm/d]\",\n",
    "     xlim=plot_range,ylim=plot_range, pch=1)\n",
    "points(Precip_PSL_df$Precip_Zurich[ind_test],tree.Precip.test.prediction,col=\"navyblue\", pch=2)\n",
    "points(Precip_PSL_df$Precip_Zurich[ind_test],rf.Precip.test.prediction,col=\"darkgreen\", pch=5)\n",
    "legend(\"topleft\",\n",
    "       legend=c(sprintf(\"Analouge (%.2f / %.2f)\",\n",
    "                        MSE(Precip_PSL_df$Precip_Zurich[ind_test],knn.Precip.test.prediction),\n",
    "                        R2(Precip_PSL_df$Precip_Zurich[ind_test],knn.Precip.test.prediction)),\n",
    "                sprintf(\"Optimised tree (%.2f / %.2f)\",\n",
    "                        MSE(Precip_PSL_df$Precip_Zurich[ind_test],tree.Precip.test.prediction),\n",
    "                        R2(Precip_PSL_df$Precip_Zurich[ind_test],tree.Precip.test.prediction)),\n",
    "                sprintf(\"Random Forest (%.2f / %.2f)\",\n",
    "                        MSE(Precip_PSL_df$Precip_Zurich[ind_test],rf.Precip.test.prediction),\n",
    "                        R2(Precip_PSL_df$Precip_Zurich[ind_test],rf.Precip.test.prediction))),\n",
    "      pch=c(1,2,5),col=c(\"salmon\",\"navyblue\",\"darkgreen\"), title=\"Model (MSE / R2)\")\n",
    "abline(0,1,col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Questions</b> \n",
    "\n",
    "- How would you judge the predictive power of the knn (k=1) approach? \n",
    "- What is the model actually doing here?\n",
    "- Would you think this method could be used for skillfull forecasting?\n",
    "- Interpret the \"layered\" predictions of the optimised tree (blue triangles).\n",
    "- Did the tree-based models perform better or worse then the analogue (knn, k=1) method?\n",
    "- Which feature(s) of random forest make it advantegous in this setting?\n",
    "- How can one explain that those (much more expensive) tree method do not significantly outperform the analogue method?\n",
    "    \n",
    "</dif>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (iacr_2020_test)",
   "language": "R",
   "name": "iacr_2020_test"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
